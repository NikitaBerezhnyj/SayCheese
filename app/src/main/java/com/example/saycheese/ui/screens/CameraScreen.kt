package com.example.saycheese.ui.screens

import android.util.Log
import androidx.camera.core.CameraSelector
import androidx.camera.core.ImageCapture
import androidx.compose.foundation.background
import androidx.compose.foundation.layout.*
import androidx.compose.material3.Text
import androidx.compose.runtime.*
import androidx.compose.ui.Alignment
import androidx.compose.ui.Modifier
import androidx.compose.ui.graphics.Color
import androidx.compose.ui.platform.LocalContext
import androidx.compose.ui.platform.LocalLifecycleOwner
import androidx.compose.ui.unit.dp
import androidx.lifecycle.Lifecycle
import androidx.lifecycle.LifecycleEventObserver
import com.example.saycheese.data.CameraSettingsManager
import com.example.saycheese.ui.components.*
import com.example.saycheese.utils.PermissionUtils
import com.example.saycheese.utils.SpeechRecognizerHelper
import com.example.saycheese.utils.takePhoto
import kotlinx.coroutines.delay
import kotlinx.coroutines.launch

@Composable
fun CameraScreen() {
    val context = LocalContext.current
    val lifecycleOwner = LocalLifecycleOwner.current
    val coroutineScope = rememberCoroutineScope()
    val settingsManager = remember { CameraSettingsManager(context) }

    val (savedLensFacing, savedFlashEnabled, savedGridEnabled, savedTimeSecond, savedSpeechRecognizationEnabled) =
        settingsManager.loadCameraSettings()

    var lensFacing by remember { mutableStateOf(savedLensFacing) }
    val cameraSelector = CameraSelector.Builder().requireLensFacing(lensFacing).build()
    var flashEnabled by remember { mutableStateOf(savedFlashEnabled) }
    val imageCapture = remember { mutableStateOf<ImageCapture?>(null) }
    var flashVisible by remember { mutableStateOf(false) }
    var gridEnabled by remember { mutableStateOf(savedGridEnabled) }
    var settingsVisible by remember { mutableStateOf(false) }
    var timerSeconds by remember { mutableStateOf(savedTimeSecond) }
    var timerActive by remember { mutableStateOf(false) }
    var speechRecognizationEnabled by remember { mutableStateOf(savedSpeechRecognizationEnabled) }

    val hasPermissions = remember {
        PermissionUtils.hasCameraPermission(context) && PermissionUtils.hasAudioPermission(context)
    }

    val speechHelper = remember { SpeechRecognizerHelper(context) }
    var speechModelInitialized by remember { mutableStateOf(false) }
    var speechStatus by remember { mutableStateOf("–Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è...") }

    LaunchedEffect(Unit) {
        if (hasPermissions) {
            speechStatus = "–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ..."
            try {
                speechHelper.initModel()
                speechModelInitialized = true
                speechStatus = "–ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –¥–æ —Ä–æ–±–æ—Ç–∏"
                Log.d("SpeechRecognition", "Vosk model loaded successfully")
            } catch (e: Exception) {
                Log.e("SpeechRecognition", "Model init failed", e)
                speechStatus = "–ü–æ–º–∏–ª–∫–∞ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó –º–æ–¥–µ–ª—ñ"
                speechModelInitialized = false
            }
        }
    }

    fun takePicture() {
        val capture = imageCapture.value
        if (capture == null) {
            Log.e("CameraX", "‚ùå ImageCapture is null - camera not ready yet")
            return
        }
        Log.d("CameraX", "‚úÖ Taking picture with valid ImageCapture")
        takePhoto(context, capture) { flashVisible = true }
    }

    fun startTimerPhoto() {
        if (timerSeconds > 0) {
            timerActive = true
            Log.d("TIMER_BUTTON", "Timer started for $timerSeconds seconds")
        } else {
            takePicture()
        }
    }

    fun onTimerFinish() {
        timerActive = false
        coroutineScope.launch {
            delay(100)
            takePicture()
        }
    }

    DisposableEffect(lifecycleOwner, speechModelInitialized, speechRecognizationEnabled) {
        val observer = LifecycleEventObserver { _, event ->
            when (event) {
                Lifecycle.Event.ON_RESUME -> {
                    Log.d("SpeechRecognition", "ON_RESUME event")
                    if (speechRecognizationEnabled && speechModelInitialized && speechHelper.isModelReady()) {
                        Log.d("SpeechRecognition", "‚úÖ Starting listening...")
                        speechHelper.startListening(
                            onCheeseHeard = {
                                Log.d("SpeechRecognition", "üßÄ Cheese command received!")
                                if (!timerActive) takePicture()
                            },
                            onTimerHeard = {
                                Log.d("SpeechRecognition", "‚è±Ô∏è Timer command received!")
                                if (!timerActive) startTimerPhoto()
                            }
                        )
                        speechStatus = "üé§ –°–ª—É—Ö–∞—é –∫–æ–º–∞–Ω–¥—É..."
                    } else {
                        val reason = when {
                            !speechRecognizationEnabled -> "–≤–∏–º–∫–Ω–µ–Ω–æ –≤ –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è—Ö"
                            !speechModelInitialized -> "–º–æ–¥–µ–ª—å —â–µ –∑–∞–≤–∞–Ω—Ç–∞–∂—É—î—Ç—å—Å—è"
                            !speechHelper.isModelReady() -> "–º–æ–¥–µ–ª—å –Ω–µ –≥–æ—Ç–æ–≤–∞"
                            else -> "–Ω–µ–≤—ñ–¥–æ–º–∞ –ø—Ä–∏—á–∏–Ω–∞"
                        }
                        speechStatus = "–†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –Ω–µ –∞–∫—Ç–∏–≤–Ω–µ: $reason"
                        Log.d("SpeechRecognition", "Not starting listener: $reason")
                    }
                }
                Lifecycle.Event.ON_PAUSE -> {
                    Log.d("SpeechRecognition", "ON_PAUSE event - stopping listener")
                    speechHelper.stopListening()
                    speechStatus = "‚è∏Ô∏è –ü—Ä–∏–∑—É–ø–∏–Ω–µ–Ω–æ"
                }
                Lifecycle.Event.ON_DESTROY -> {
                    Log.d("SpeechRecognition", "ON_DESTROY event - releasing resources")
                    speechHelper.release()
                    speechStatus = "‚èπÔ∏è –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞—á –∑—É–ø–∏–Ω–µ–Ω–æ"
                }
                else -> {}
            }
        }
        lifecycleOwner.lifecycle.addObserver(observer)
        onDispose {
            lifecycleOwner.lifecycle.removeObserver(observer)
            speechHelper.release()
        }
    }

    if (!hasPermissions) {
        Box(modifier = Modifier.fillMaxSize(), contentAlignment = Alignment.Center) {
            Text(text = "–ü–æ—Ç—Ä—ñ–±–µ–Ω –¥–æ–∑–≤—ñ–ª –Ω–∞ –∫–∞–º–µ—Ä—É —Ç–∞ –º—ñ–∫—Ä–æ—Ñ–æ–Ω", color = Color.White)
        }
        return
    }

    Box(modifier = Modifier.fillMaxSize()) {
        Column(
            modifier = Modifier
                .fillMaxSize()
                .background(Color.Black)
                .padding(
                    top = WindowInsets.statusBars.asPaddingValues().calculateTopPadding(),
                    bottom = WindowInsets.navigationBars.asPaddingValues().calculateBottomPadding()
                )
        ) {
            TopBar(
                flashEnabled = flashEnabled,
                onFlashToggle = {
                    flashEnabled = !flashEnabled
                    settingsManager.saveCameraSettings(
                        lensFacing, flashEnabled, gridEnabled, timerSeconds, speechRecognizationEnabled
                    )
                },
                onSettingsClick = { settingsVisible = true }
            )

            Box(
                modifier = Modifier
                    .weight(1f)
                    .fillMaxWidth(),
                contentAlignment = Alignment.Center
            ) {
                CameraPreview(
                    modifier = Modifier.fillMaxSize(),
                    cameraSelector = cameraSelector,
                    flashEnabled = flashEnabled,
                    imageCapture = imageCapture,
                    lensFacing = lensFacing
                )
                if (gridEnabled) GridOverlay()
                if (flashVisible) FlashOverlay { flashVisible = false }
                if (timerActive)
                    TimerCounter(timerSeconds, ::onTimerFinish, Modifier.align(Alignment.Center))
            }

            BottomBar(
                imageCapture = imageCapture,
                onTakePhoto = { takePicture() },
                onTakePhotoWithTimer = { startTimerPhoto() },
                onSwitchCamera = {
                    if (!timerActive) {
                        lensFacing =
                            if (lensFacing == CameraSelector.LENS_FACING_BACK)
                                CameraSelector.LENS_FACING_FRONT
                            else
                                CameraSelector.LENS_FACING_BACK
                        settingsManager.saveCameraSettings(
                            lensFacing, flashEnabled, gridEnabled, timerSeconds, speechRecognizationEnabled
                        )
                    }
                }
            )
        }

        if (speechRecognizationEnabled) {
            Box(
                modifier = Modifier
                    .align(Alignment.BottomCenter)
                    .padding(bottom = 120.dp)
                    .background(Color.Black.copy(alpha = 0.7f))
                    .padding(horizontal = 16.dp, vertical = 8.dp)
            ) {
                Text(text = speechStatus, color = Color.White)
            }
        }

        if (settingsVisible) {
            SettingsDialog(
                gridEnabled = gridEnabled,
                timerSeconds = timerSeconds,
                onGridChange = {
                    gridEnabled = it
                    settingsManager.saveCameraSettings(
                        lensFacing, flashEnabled, gridEnabled, timerSeconds, speechRecognizationEnabled
                    )
                },
                onTimerChange = {
                    timerSeconds = it
                    settingsManager.saveCameraSettings(
                        lensFacing, flashEnabled, gridEnabled, timerSeconds, speechRecognizationEnabled
                    )
                },
                onDismissRequest = { settingsVisible = false },
                listeningEnabled = speechRecognizationEnabled,
                onListeningChange = { enabled ->
                    speechRecognizationEnabled = enabled
                    settingsManager.saveCameraSettings(
                        lensFacing, flashEnabled, gridEnabled, timerSeconds, enabled
                    )
                    if (enabled && speechModelInitialized && speechHelper.isModelReady()) {
                        speechHelper.startListening(
                            onCheeseHeard = { if (!timerActive) takePicture() },
                            onTimerHeard = { if (!timerActive) startTimerPhoto() }
                        )
                        speechStatus = "üé§ –°–ª—É—Ö–∞—é –∫–æ–º–∞–Ω–¥—É..."
                    } else {
                        speechHelper.stopListening()
                        speechStatus = "‚è∏Ô∏è –ü—Ä–∏–∑—É–ø–∏–Ω–µ–Ω–æ"
                    }
                }
            )
        }
    }
}